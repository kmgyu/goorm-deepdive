java io

표준 입출력
콘솔 입출력


네트워크 io

api에서 데이터가 뭐가 올지 모름.
json 대세가 되면서 프레임워크나 라이브러리가 기본으로 제공해주기 시작.

뭐든간에 일단 응답받으면 json 파싱해서 다음 프로세스~

웹 비즈니스에 대한 이해는 비전공자가 더 이해하기 유리할 수 있다.
이거 길러야 한다
요구사항 분석, 이해, 어떻게 구현~ 같은 계획 세우기



메모리 기반 io
메모리에 있는 데이터를 마치 파일이나 스트림처럼 처리하는 기법

jvm 메모리 영역
주로 힙영역 의미한다고 함.

디스크 vs 메모리
파일 io? 힙 - 디스크 (느림)
메모리 io? 힙 내에서만 이등 (빠름)

1. **테스트 코드**
2. **데이터 변환**
3. **임시 데이터 처리**
4. **API 응답 처리
등에서 사용


직렬화 io
자바 객체를 바이트로 변환해서 저장/전송
현재는 객체 데이터 전송 시 직렬화보다 json 형태로 변환해서 사용?
바이트로 변환하다 json으로 변환한다는 뜻...

직렬화 보안 위험
역직렬화 공격
가젯 체인
신뢰할 수 없는 데이터

이것 외에도 호환성 이슈 등 문제가 많았다. 그래서 json으로 대체됨.


파일 io
전통방식과 현재방식으로 구분

|구분|IO (전통방식)|NIO (현재방식)|
|---|---|---|
|**처리방식**|블로킹 (기다림)|논블로킹 (즉시 반환)|
|**데이터흐름**|스트림 (한방향)|채널 (양방향)|
|**동시처리**|어려움|가능|
|**성능**|느림|빠름|
블로킹은 파일 읽기가 끝날 때까지 프로그램이 멈추나, 논블로킹은 파일 읽기 요청하고 바로 다른 작업 가능

정확히는 스레드가 멈춘다.
블로킹/논블로킹은 동기/비동기와 다른 개념이다. 보통 조합해서 쓰게 됨.

NIO는 톰캣 7이상부터 nio 커넥터가 기본값으로 변경되고 이런 건 우리가 신경 쓸 필요가 없다고 함...
나 멀티 파트 파일 할 때 스트림 열었던 거 같은데? 아닌가?

아무튼 요즘은 거의 모든 서버가 nio 쓴다!

웹 업로드

일반 업로드
서버 예제
```java
//Spring Boot (실무 표준) 
@PostMapping("/upload") 
public String upload(@RequestParam("file") MultipartFile file) {    

   file.transferTo(new File("uploads/" + file.getOriginalFilename())); 
   return "success"; 
   
}
```

대용량 솔루션: 클라이언트 청크
2000년대 웹 업로드?
액티브X, 어도비 플래시, 자바 애플릿 업로더 등이 있었다.
http 우회, ftp/소켓 직접 사용하는 방식인데 보안문제로 모두 차단됨


실무 라이브러리, 도구
- **Resumable.js (2013~)**: 재시작 가능한 업로드
- **Fine Uploader (2010~)**: 상업용 고급 업로더
- **Dropzone.js (2012~)**: 드래그앤드롭 지원


**일반 업로드:**

```java
@PostMapping("/upload")
public String upload(@RequestParam("file") MultipartFile file) {
    file.transferTo(new File("uploads/" + file.getOriginalFilename()));
    return "success";
}
```

**청크 업로드:**

```java
@PostMapping("/upload-chunk")
public String uploadChunk(
    @RequestParam("chunk") MultipartFile chunk,
    @RequestParam("chunkIndex") int chunkIndex,
    @RequestParam("totalChunks") int totalChunks,
    @RequestParam("fileName") String fileName) {
    
    // 청크를 임시 저장
    saveChunk(chunk, chunkIndex, fileName);
    
    // 모든 청크가 도착했으면 합치기
    if (isAllChunksReceived(fileName, totalChunks)) {
        mergeChunks(fileName, totalChunks);
        deleteTemporaryChunks(fileName);
    }
    
    return "success";
}
```

**주요 변경사항:**

- 각 청크를 개별적으로 받아서 임시 저장
- 청크 순서와 전체 개수 관리
- 모든 청크 수신 후 파일 병합
- 임시 파일들 정리

단순한 한 번의 업로드가 여러 번의 요청으로 바뀌면서 서버 로직이 복잡해집니다.

- **클라우드 직접 업로드**: AWS S3, Google Cloud Storage 등 활용
**클라우드 직접 업로드 (Presigned URL 방식):**

**1. 전체 흐름:**

```
브라우저 → 서버 (업로드 권한 요청)
       ← 서버 (임시 URL 발급)
브라우저 → AWS S3 (직접 업로드)
       ← AWS S3 (업로드 완료)
브라우저 → 서버 (업로드 완료 알림)
```

##### **높은 동시 접속 환경:**
- **로드밸런싱**: 여러 서버로 부하 분산
- **CDN + 클라우드**: 정적 파일 처리 최적화


부록
스트림 api?
컬렉션 데이터를 스트림처럼 처리...

---

DB 페이징과 검색

요청 과 응답 흐름

📤 요청 (Request)
- **필수**: 페이지 번호 (page=3)
- **옵션**: 페이지 크기 (size=10) - 없으면 서버 기본값 사용
옵션도 있어야 서버가 사용 가능하다고한다? 그럼 왜 옵션이라 써둔 거임...?

**🔧 서버 내부 계산**
- **OFFSET**: 건너뛸 데이터 개수 = (page-1) × size = 20
- **LIMIT**: 가져올 데이터 개수 = size = 10
  
  의미 : 20개부터 10개를 가져와 (OFFSET=20, LIMIT=10)
실제로 DB에선 어떻게 처리됨?

**📥 응답 (Response)**

- **필수**:
    - 결과 리스트 (실제 데이터)
    - 현재 페이지 번호 (page=3)
    - 전체 데이터 수 (페이징 네비게이션 계산용)
- **불필요**: 페이지 크기 - 클라이언트가 이미 알고 있거나 고정값

특히 전체 데이터 수가 핵심인 이유는:
- 페이지 버튼 개수 계산 및 이전/다음 버튼 제어


성능 최적화 포인트

### **인덱스 설정**

```sql
-- 검색 성능 향상을 위한 인덱스
CREATE INDEX idx_board_title ON board(title);
CREATE INDEX idx_board_content ON board(content);
CREATE INDEX idx_board_created_at ON board(created_at);
CREATE INDEX idx_board_author ON board(author);

-- 복합 인덱스 (자주 함께 사용되는 컬럼)
CREATE INDEX idx_board_search ON board(title, content, created_at);
```

### **쿼리 최적화**

- **COUNT(*) 대신 COUNT(id)**: NULL 값이 많은 경우
- **EXISTS 사용**: JOIN 대신 서브쿼리로 성능 향상
- **OFFSET 방식의 한계점**: 페이지가 뒤로 갈수록 성능 급격히 저하
    - 문제: `OFFSET 1000000`은 데이터베이스가 100만 개 레코드를 건너뛰어야 함
    - 해결: 큰 OFFSET은 가능한 피하거나 커서 기반 페이징 사용

### **대용량 데이터 페이징 대안: 커서 기반 페이징**

```sql
-- 전통적 OFFSET 방식 (느림)
SELECT * FROM board 
ORDER BY id DESC 
LIMIT 10 OFFSET 1000000;  -- 매우 느림!

-- 커서 기반 페이징 (빠름)
-- 첫 페이지
SELECT * FROM board 
ORDER BY id DESC 
LIMIT 10;

-- 다음 페이지 (마지막 조회된 ID가 500이라고 가정)
SELECT * FROM board 
WHERE id < 500 
ORDER BY id DESC 
LIMIT 10;

-- 이전 페이지 (첫 번째 조회된 ID가 510이라고 가정)
SELECT * FROM board 
WHERE id > 510 
ORDER BY id ASC 
LIMIT 10;
```

**커서 기반 페이징 장점:**

- **일정한 성능**: 페이지 위치와 상관없이 항상 빠름
- **실시간 데이터**: 새로운 데이터 추가에도 일관성 유지
- **대용량 처리**: 수백만 건 데이터도 빠르게 처리

**커서 기반 페이징 단점:**

- **특정 페이지 이동 불가**: "5페이지로 이동" 같은 기능 구현 어려움
- **복잡한 정렬**: 여러 컬럼 정렬 시 구현 복잡
- **UI 제약**: 페이지 번호 대신 "이전/다음" 버튼만 사용 가능

커서 기반 페이징은 **무한 스크롤**이나 **타임라인** 형태의 UI에 최적화된 방식입니다.

- **Instagram, Facebook 피드**: 아래로 스크롤하면 계속 로딩
- **Twitter 타임라인**: "더 보기" 버튼이나 무한 스크롤
- **YouTube 댓글**: 스크롤 방식으로 계속 로딩

반대로 **게시판이나 관리자 페이지**처럼 "3페이지로 바로 이동"이 필요한 곳에는 전통적인 OFFSET 방식이 더 적합

### **캐싱 전략**

- **페이지별 캐싱**: 자주 접근하는 페이지 정보 캐싱
- **검색 결과 캐싱**: 동일한 검색어 결과 캐싱
- **전체 개수 캐싱**: COUNT 결과를 주기적으로 업데이트


다음주는 DB 좀 할 예정이라고 함.