> 여기서는 캐싱을 구현할 것이다.
> 총 3가지의 구현 방법을 알아본다.

# 기초 기능 구현

캐싱을 위한 기능부터 구현해 보자.

기능 이름은 board로, 간단하게 게시판 내용을 보여주는 것이다.

아래는 캐싱을 위한 코드 스니펫의 일부분이다.
```java
// BoardService
// @Cacheable("board")  
public BoardResponseDTO findById(Long id) {  
  Board board = boardRepository.findById(id).orElse(null);  
  
  if  (board == null) {  
    return null;  
  }  
  
  return BoardResponseDTO.builder()  
          .id(board.getId())  
          .title(board.getTitle())  
          .content(board.getContent())  
          .build();  
}
```

캐싱을 위한 데이터의 경우 배치 잡을 이용해 처리했다.
핸들러 메서드를 통해 트리거링하도록 하여 잘못 건드려서 실행할 때마다 작업이 생성되는 불상사를 막았다.
단일 board를 생성하는 핸들러 메서드는 구현하지 않았으니 참고.

> #todo 추후 로커스트를 통해 성능 측정 시 쓰기 작업을 추가해서 DB I/O도 고려를 해야 할까?
> 하하 돈이 땅에서 나오나 보구나
> 근데 궁금하긴 함. aws rds도 마이그레이션으로 초기 데이터만 추가해주자.

## 추가 세팅

새 기능 추가 시 기존 데이터와 충돌이 생길 수 있다.

본인은 이미 사용자 테이블에 1만 개의 데이터가 존재했기 때문에 한번 더 배치 잡을 실행시키고 싶지 않았다.

```properties
spring.jpa.hibernate.ddl-auto=create-only
```
해당 설정을 사용하여 기존 테이블 생성 시 충돌을 발생시켜 막고, 없는 테이블만 생성시켜주자.

![[batch-data-capture.png]]

데이터는 이렇게 작성했다.
사실 aws rds에서도 DB에 무리가게 하기 싫어서 최대한 간단한 데이터로 작성했다.
만약 캐싱을 사용하지 않고 요청 시 자체적으로 20ms 정도를 추가로 기다리도록 할 예정이다. (해당 기능을 계산이 필요한 작업이라고 가정한다.)

## 지연 시간

캐싱은 지연 시간이 길 수록 효과적이다. DB 측에서 가져와 백엔드에서 추가로 처리하는 작업이 매우 길다던지, DB I/O가 길다던지...
여기서는 DB 측에서 백엔드가 추가로 20ms 만큼의 작업을 해줘야 한다는 가상의 시나리오로 설정하였다.

이를 구현하는 것은 다음과 같이, Thread.sleep을 해주면 된다.

```
@Cacheable("board")  
public BoardResponseDTO findById(Long id) {  
  try {  
    Thread.sleep(20); // 20ms 대기  
  } catch (InterruptedException e) {  
    Thread.currentThread().interrupt();  
  }  
  
  Board board = boardRepository.findById(id).orElse(null);  
  
  if  (board == null) {  
    return null;  
  }  
  
  return BoardResponseDTO.builder()  
          .id(board.getId())  
          .title(board.getTitle())  
          .content(board.getContent())  
          .build();  
}
```



로컬 테스트

![[before-latency.png]]
![[after-latency.png]]

단일 요청 기준 평균 19~30ms의 지연이 걸렸으나, 40~60ms의 지연이 걸렸다.

이번엔 locust를 이용해 500개의 사용자로 0,3초에서 5초마다 가져왔다.
> 참고: 해당 테스트에서는 캐싱 기능을 활용한 상태이다.
![[locust-1.png]]

![[locust-2.png]]


---

# 캐싱 구현

이 프로젝트에서는 [공식문서](https://docs.spring.io/spring-boot/reference/io/caching.html)를 바탕으로 구현하였다.
기본적으로는 9가지의 캐싱 방식을 지원하나, 3가지의 방법만을 알아본다.

#todo JCache를 넣을까 말까 xml 쓰는데 쓰기 싫다.

1. 스프링 제공 캐시 - ConcurrentHashMap
만약 아무 설정도 하지 않을 경우, 콜렉션 중 하나인 ConcurrentHashMap을 사용하게 된다.
2. 스프링 제공 캐시 - Caffeine
ConcurrentHashMap을 제외한 Cache Provider 중 가장 간단한 방법으로, properties/yaml으로 설정해줄 수 있다.
3. 레디스를 이용한 캐시
외부 캐시 저장소 중 하나이며, 공식 문서에서도 소개되는 방법 중 하나이다.


Cache 사용 시 기본적으로 properties에 아래와 같이 @Cacheable에서 지정해준 캐시의 이름을 추가해야 한다.
필수적이기 때문에 꼭 써주자. 아래에서는 생략한 내용이다!
```properties
spring.cache.cache-names=cachename1,cachename2
```


## 1. ConcurrentHashMap

참고자료 : [java se8 공식문서](https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ConcurrentHashMap.html)
> "*Java ConcurrentHashMap은 진짜 유명한 콜렉션임*"

ConcurrentHashMap은 이름대로 thread-safe한 HashMap이다.

properties에 따로 CacheProvider를 지정해주지 않는다면 자바의 컬렉션인 ConcurrentHashMap을 이용해 캐싱을 한다.

이것의 단점은, 만료 시간이라는 개념이 없어 기존 데이터를 명시적으로 삭제하지 않는 경우 그대로 남아있다는 점이다. 따라서 메모리에 치명적일 가능성이 크다.


## 2. Caffeine

Caffeine은 구글 개발자들이 만든 Guava의 인터페이스를 기반으로 캐시를 제공하는 Cache Provider이다.
[github caffeine wiki](https://github.com/ben-manes/caffeine/wiki/Guava)

기본적으로 ConcurrentMap과 유사하나 가장 근본적 차이점은 캐시 만료시간이 추가되었다. 
자동 캐시 로딩으로 인해 항목을 자동으로 제거하지 않더라도 유용할 수 있다고 한다.
> ConcurrentMap은 단순히 null을 출력하기 때문에 더 스마트한 getter를 지원한다는 것으로 보임. 이것은 어플리케이션 개발자보다는 프레임워크 개발자의 DX에 개선이 있다는 의미로 보인다.

```properties  
spring.cache.caffeine.spec=maximumSize=500,expireAfterAccess=600s
```

더 많은 설정 값은 이곳을 참고하자.
[javadoc-caffeine-spec](https://www.javadoc.io/doc/com.github.ben-manes.caffeine/caffeine/2.2.2/com/github/benmanes/caffeine/cache/CaffeineSpec.html)

## 3. Redis

가장 내용이 길다.

레디스는 외부 설정을 해야 한다. 여기서는 백엔드 기준 구현만 하겠다.

공식 문서에 따르면 RedisCacheManager 또한 레디스가 사용 가능하고 세팅되어 있을 시(의존성을 가리키는 것으로 보임.) 자동으로 설정된다.
`spring.cache.redis.*`를 통해 추가적인 세팅을 해줄 수 있다.

아래는 캐시 TTL을 설정하는 예시이다.
```properties
spring.cache.redis.time-to-live=10m
```

#todo Redis config 클래스를 만들어주는 이유?

https://railly-linker.tistory.com/61
이런 것들 보면 다 그러던데, 왤까...

> gpt의 말로는... 단순 연결 설정을 넘어, Redis를 애플리케이션의 캐싱 전략·시리얼라이징 정책·운영 환경에 맞게 세밀하게 제어하기 위해서 라고 한다.
> 프로필 분리나 다중 인스턴스 연결, 커넥션 풀 튜닝 같은 것이 주된 이유인듯.
> 클러스터/센티넬 구성, 캐시 매니저 명시 등 레디스에서도 구현체가 다양하니 이런 것들을 명시하는 것도 있을 듯...

클러스터 노드를 해석하지 못하고 있다.

(1) `Could not connect to Redis at redis-node-1:6479: No address associated with hostname`

→ **호스트 이름(`redis-node-1`)을 DNS에서 찾지 못함.**  
즉, 이 이름을 IP로 변환할 수 없다는 뜻이다.  
이건 “Redis 서버가 없다”가 아니라 “클라이언트가 이름을 인식하지 못한다”는 문제다.

(2) `Could not connect to Redis at redis-node-1:6479: Connection refused`

→ 해당 주소는 인식했지만, **해당 포트(6479)에 Redis 프로세스가 열려 있지 않음.**

즉, Docker나 네트워크 레벨에서 노드가 잘못 설정됐을 확률이 높다.

config를 찾지 못하는 것도 문제

[[redis-issues]]
다른 여러 문제들도 해결해주었다.

> JWT 토큰을 사용할 때는 영속 계층 형식으로 사용하게 된다. 이때는 레디스는 RedisTemplate 또는 redis repository를 통해 데이터에 접근해야 한다.
> 자세한 건 [참고자료](https://wildeveloperetrain.tistory.com/244)와 [이 자료](https://velog.io/@turtledev/Spring-Redis-Redis-Template%EA%B3%BC-Redis-Repository)를 참고하자.
> 여기서는 간단한 방식인 redis repository를 사용하려 했으나, 이것은 영속 계층 형식으로 사용하는 것이다. 우리는 이렇게 사용하지 않는다.

아마 DB가 다르다 보니 엔티티도 캐시용과 영구 DB용으로 나뉘고 repository도 동일하게 두 개로 나뉘어 관리하는 방식인 것 같다.
DDD에서 보았던 방식처럼 관심사를 서로 분리하는 것도 이 때문인 듯.

아무튼 기본 설정인 @Cacheable만으로도 되야 하는 게 정상인데, docker network와 host network가 정상적으로 통신하지 않는 것이 지금의 이슈였다.
따라서 백엔드를 빌드해서 그걸 컨테이너로 띄워줄 것이다.

properties 세팅은 생략하였다.

docker compose의 세팅을 보자.
```yml
  dbms:
    image: mariadb:latest
    hostname: mariadb-node
    ports:
      - 3306:3306
    networks:
      - redis-cluster-compose

  spring-backend:
    image: kmgyu/spring_batch_instruction:scenario-login-redis-caching
    hostname: backend-node
    ports:
      - 8080:8080
    networks:
      - redis-cluster-compose
    # volumes:
    #   - ./data/backend:/
```
db와 백엔드를 간단하게 추가해주었다. 브랜치별로 태깅을 다르게 했으나 본인 프로젝트에서는 알아서 변경해주자.

그럼에도 불구하고 UnknownHostException이 생겨버리셨다.
이번에는 마리아db 노드에서 생겼다.
중간에 세팅에서도 depends on을 넣어주다 알게된 것이다.
dbms라고 작성되어있는 부분이 서비스 이름인데, hostname이 명칭이 되는줄 알고 착각한 것...
그럼에도 unknownHost가 뜨긴 한다.

로그를 통해 오류를 알아냈다.
바로 mariadb host 설정을 안해주는 것... 이딴 것 때문에 1시간 넘게 날렸다. 이런 거 하지말고 바로바로 로그 확인해주자 자살마렵다.

설정해줬더니... 이번엔 depends on이 있음에도 스프링이 먼저 열리는 문제가 발생한다.
알아보니 컨테이너 시작 기준이라고 한다. 서버 실행은 스프링이 더 빨라서 이런 문제가 발생하는 것 같다.
```yml
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost", "-u", "root", "-p${MARIADB_ROOT_PASSWORD}"]
      interval: 5s
      timeout: 5s
      retries: 10
      start_period: 10s # <-- 컨테이너 시작 후 10초 대기 후 healthcheck 시작
```
진짜 너무 싫다... 이거 넣어주면 10초 대기하고 시작한다.

---

# 캐시 전략

자료
https://escapefromcoding.tistory.com/703

캐시 전략을 사용해보자.
기본 어노테이션은 너무 한정적이다.

테스트 코드에서는 구현하지 않고 기본값을 사용하여 그냥 넘어갈 것이다. 하지만 우리는 이걸 알아보아야 한다.
