> EC2 load balancer를 구축하여 기본적인 로드밸런서의 역할을 알아본다.


로드밸런싱 유형
L4/L7
#todo L4/L7의 차이

여기선 L4를 사용한다.



nginx reverse proxy 사용하기

왜 nginx reverse proxy인가?

aws에서는 AWS ELB라는 선택지도 있다.
왜냐면... 구현이 간단하고 EC2 인스턴스를 그렇게 많이 사용하지 않을 것이기 때문이다.

nginx 설치
```
sudo apt update
sudo apt install -y nginx
sudo systemctl enable --now nginx
```

설정파일 세팅하기
```
nano /etc/nginx/conf.d/app.conf
```

사실 해당 파일은 존재하지 않는다.
기본 설정 경로는 `/etc/nginx/conf.d/*.conf`이지만 설정파일 까보면 다음과 같은 줄이 들어가있다.

```
http {
	# ... some important settings
    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;

	##
	# Virtual Host Configs
	# here is the thing
	##

	include /etc/nginx/conf.d/*.conf;
	include /etc/nginx/sites-enabled/*;

    # ... some rest of settings
}
```

`*.conf`를 통해 다른 앱들의 설정을 include 해줄 수 있다.


아래 내용을 채워주자.
```
# upstream pool (backend servers)
# default algorithm : round robin, automatic rerouting by fail
upstream backend {
    # selecting algorithm
    # sticky connection needed : ip_hash
    # connection-based load : least_conn
    
    # ip_hash;
    least_conn;

    # server register (private_ip:port)
    server your.private.ip.port:8080 max_fails=3 fail_timeout=10s;
    server your.private.ip.port:8080 max_fails=3 fail_timeout=10s;

    # keepalive connection to performance improve
    # for proxy backend connection recycling?
    keepalive 64;
}

# WebSocket and HTTP upgrade support
map $http_upgrade $connection_upgrade {
    default upgrade;
    ''      close;
}

server {
    listen 80; # client request port
    # server_name _;  # domain setting

	location / {
		# client host setting
		proxy_set_header Host $host; 
		
		# using upstream server specify
		# proxy setting
		proxy_http_version 1.1;
		proxy_set_header Host $host;
		proxy_set_header X-Real-IP $remote_addr;
		proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
		
        # For WebSocket
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection $connection_upgrade;
		
		# 설정한 이름으로 요청 보내기
		# request to set name
		proxy_pass http://backend; 
	}
    # if you using HTTPS, this will 80 → 443 redirect
    # return 301 https://$host$request_uri;
}
```

> #todo 
> algorithm settings
> http upgrade?
> for websocket setting?
> 


https를 위한 블록
```
# 아래 블록은 HTTPS 사용시에만 사용할 것.
# HTTPS 서버블록 (Let's Encrypt 발급 후 주석 해제하여 사용)
server {
    listen 443 ssl http2;
    server_name _;  # 도메인으로 교체

    # 인증서 경로(아래 8단계에서 발급)
    ssl_certificate     /etc/letsencrypt/live/your.domain/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/your.domain/privkey.pem;

    # 기본 프록시 설정
    client_max_body_size 50m;
    send_timeout 30s;

    location / {
        proxy_http_version 1.1;
        proxy_set_header Host              $host;
        proxy_set_header X-Real-IP         $remote_addr;
        proxy_set_header X-Forwarded-For   $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;

        # WebSocket 지원
        proxy_set_header Upgrade    $http_upgrade;
        proxy_set_header Connection $connection_upgrade;

        # 타임아웃 및 리트라이
        proxy_connect_timeout   2s;
        proxy_send_timeout     30s;
        proxy_read_timeout     30s;
        proxy_next_upstream error timeout http_502 http_503 http_504;

        proxy_pass http://backend_pool;
    }

    # 헬스패스(옵션): nginx 자체 확인용
    location = /nginx/health {
        return 200 'ok';
        add_header Content-Type text/plain;
    }

    # 로그 포맷(업스트림 응답시간 포함)
    access_log /var/log/nginx/app_access.log main;
}
```

이제 설정 파일을 저장하고 다음 명령어를 입력해준다.
```
sudo nginx -t
sudo systemctl reload nginx

# 한 줄 명령어
sudo nginx -t && sudo systemctl reload nginx
```

---
# 참고자료

로드밸런싱
[참고자료](https://velog.io/@kimjiwonpg98/Nginx-%EB%A1%9C%EB%93%9C%EB%B0%B8%EB%9F%B0%EC%8B%B1-%EA%B0%9C%EB%85%90-%EB%B0%8F-%EA%B5%AC%EC%B6%95)

nginx 설정
[참고자료](https://velog.io/@kimjiwonpg98/Nginx-%EB%A1%9C%EB%93%9C%EB%B0%B8%EB%9F%B0%EC%8B%B1-%EA%B0%9C%EB%85%90-%EB%B0%8F-%EA%B5%AC%EC%B6%95)

---

# 네트워크 알고리즘? 자료


### 알고리즘 종류

|방법|설명|
|---|---|
|라운드로빈(기본값)|요청을 순서대로 처리한다.|
|least_conn(최소 연결)|각 요청을 서버에 할당된 가중치를 고려해 연결 수가 가장 적은 서버로 전송|
|ip_hash|요청이 클라이언트 IP주소로 해싱 > 한번 요청 받은 서버가 있을 때 해당 서버에만 요청을 분배|
|least_time|연결 수가 가장 적으면서 평균 응답시간이 가장 적은 쪽을 선택해서 분배 (Nginx Plus에서만 가능)|
